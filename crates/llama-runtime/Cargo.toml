[package]
name = "llama-runtime"
description = "Execution runtime for llama.rs â€” oxidizedMLX integration and backend selection"
version.workspace = true
edition.workspace = true
license.workspace = true
repository.workspace = true

[features]
default = ["cpu"]
cpu = []
metal = []

[dependencies]
llama-engine = { path = "../llama-engine", version = "0.1.0" }
llama-kv = { path = "../llama-kv", version = "0.1.0" }
llama-tokenizer = { path = "../llama-tokenizer", version = "0.1.0" }
llama-sampling = { path = "../llama-sampling", version = "0.1.0" }
thiserror.workspace = true
